{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Tabular Prediction\n\n- https://autogluon.mxnet.io/tutorials/tabular_prediction/tabular-quickstart.html"},{"metadata":{},"cell_type":"markdown","source":"## Predicting Columns in a Table - Quick Start"},{"metadata":{"trusted":true},"cell_type":"code","source":"import autogluon as ag\nfrom autogluon import TabularPrediction as task","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = task.Dataset(file_path='https://autogluon.s3.amazonaws.com/datasets/Inc/train.csv')\ntrain_data = train_data.head(500) # subsample 500 data points for faster demo\nprint(train_data.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label_column = 'class'\nprint(\"Summary of class variable: \\n\", train_data[label_column].describe())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"%%time\ndir = 'agModels-predictClass' # specifies folder where to store trained models\npredictor = task.fit(train_data=train_data, label=label_column, output_directory=dir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = task.Dataset(file_path='https://autogluon.s3.amazonaws.com/datasets/Inc/test.csv')\ny_test = test_data[label_column]  # values to predict\ntest_data_nolab = test_data.drop(labels=[label_column],axis=1) # delete label column to prove we're not cheating\nprint(test_data_nolab.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictor = task.load(dir) # unnecessary, just demonstrates how to load previously-trained predictor from file\n\ny_pred = predictor.predict(test_data_nolab)\nprint(\"Predictions:  \", y_pred)\nperf = predictor.evaluate_predictions(y_true=y_test, y_pred=y_pred, auxiliary_metrics=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = predictor.fit_summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"AutoGluon infers problem type is: \", predictor.problem_type)\nprint(\"AutoGluon categorized the features as: \", predictor.feature_types)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Regression (predicting numeric table columns)"},{"metadata":{"trusted":true},"cell_type":"code","source":"age_column = 'age'\nprint(\"Summary of age variable: \\n\", train_data[age_column].describe())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"%%time\npredictor_age = task.fit(train_data=train_data, output_directory=\"agModels-predictAge\", label=age_column, time_limits=60)\nperformance = predictor_age.evaluate(test_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Predicting Columns in a Table - In Depth\n\n- https://autogluon.mxnet.io/tutorials/tabular_prediction/tabular-indepth.html\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import autogluon as ag\nfrom autogluon import TabularPrediction as task\n\ntrain_data = task.Dataset(file_path='https://autogluon.s3.amazonaws.com/datasets/Inc/train.csv')\ntrain_data = train_data.head(500) # subsample 500 data points for faster demo (comment this out to run on full dataset instead)\nprint(train_data.head())\n\nval_data = task.Dataset(file_path='https://autogluon.s3.amazonaws.com/datasets/Inc/test.csv')\n\nlabel_column = 'occupation'\nprint(\"Summary of occupation column: \\n\", train_data['occupation'].describe())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nhp_tune = True  # whether or not to do hyperparameter optimization\n\nnn_options = { # specifies non-default hyperparameter values for neural network models\n    'num_epochs': 10, # number of training epochs (controls training time of NN models)\n    'learning_rate': ag.space.Real(1e-4, 1e-2, default=5e-4, log=True), # learning rate used in training (real-valued hyperparameter searched on log-scale)\n    'activation': ag.space.Categorical('relu', 'softrelu', 'tanh'), # activation function used in NN (categorical hyperparameter, default = first entry)\n    'layers': ag.space.Categorical([100],[1000],[200,100],[300,200,100]),\n      # Each choice for categorical hyperparameter 'layers' corresponds to list of sizes for each NN layer to use\n    'dropout_prob': ag.space.Real(0.0, 0.5, default=0.1), # dropout probability (real-valued hyperparameter)\n}\n\ngbm_options = { # specifies non-default hyperparameter values for lightGBM gradient boosted trees\n    'num_boost_round': 100, # number of boosting rounds (controls training time of GBM models)\n    'num_leaves': ag.space.Int(lower=26, upper=66, default=36), # number of leaves in trees (integer hyperparameter)\n}\n\nhyperparameters = {'NN': nn_options, 'GBM': gbm_options}  # hyperparameters of each model type\n# If one of these keys is missing from hyperparameters dict, then no models of that type are trained.\n\ntime_limits = 2*60  # train various models for ~2 min\nnum_trials = 5  # try at most 3 different hyperparameter configurations for each type of model\nsearch_strategy = 'skopt'  # to tune hyperparameters using SKopt Bayesian optimization routine\noutput_directory = 'agModels-predictOccupation'  # folder where to store trained models\n\npredictor = task.fit(train_data=train_data, tuning_data=val_data, label=label_column,\n                     output_directory=output_directory, time_limits=time_limits, num_trials=num_trials,\n                     hyperparameter_tune=hp_tune, hyperparameters=hyperparameters,\n                     search_strategy=search_strategy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = val_data.copy()\ny_test = test_data[label_column]\ntest_data = test_data.drop(labels=[label_column],axis=1)  # delete label column\n\ny_pred = predictor.predict(test_data)\nprint(\"Predictions:  \", list(y_pred)[:5])\nperf = predictor.evaluate_predictions(y_true=y_test, y_pred=y_pred, auxiliary_metrics=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = predictor.fit_summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Specifying performance metrics"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nmetric = 'balanced_accuracy'\npredictor = task.fit(train_data=train_data, label=label_column, eval_metric=metric,\n                     output_directory=output_directory, time_limits=60)\n\nperformance = predictor.evaluate(val_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model ensembling with stacking/bagging"},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"%%time\npredictor = task.fit(train_data=train_data, label=label_column, eval_metric=metric,\n                     num_bagging_folds=5, stack_ensemble_levels=1,\n                     hyperparameters = {'NN':{'num_epochs':5}, 'GBM':{'num_boost_round':100}})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"%%time\npredictor = task.fit(train_data=train_data, label=label_column, eval_metric=metric, auto_stack=True,\n                     hyperparameters = {'NN':{'num_epochs':5}, 'GBM':{'num_boost_round':100}}, time_limits = 60\n                    ) # last 2 arguments are just for quick demo, should be omitted","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Getting predictions (inference-time options)"},{"metadata":{"trusted":true},"cell_type":"code","source":"predictor = task.load(output_directory)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datapoint = test_data.iloc[[0]]  # Note: .iloc[0] won't work because it returns pandas Series instead of DataFrame\nprint(datapoint)\nprint(predictor.predict(datapoint))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_probs = predictor.predict_proba(datapoint)\nprint(class_probs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = predictor.leaderboard(val_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"i = 0  # index of model to use\nmodel_to_use = predictor.model_names[i]\nmodel_pred = predictor.predict(datapoint, model=model_to_use)\nprint(\"Prediction from %s model: %s\" % (model_to_use, model_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = predictor.predict(test_data)\npredictor.evaluate_predictions(y_true=y_test, y_pred=y_pred, auxiliary_metrics=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictor.evaluate(val_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Maximizing predictive performance"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nlong_time = 60 # for quick demonstration only, you should set this to longest time you are willing to wait\npredictor = task.fit(train_data=train_data, label=label_column, eval_metric=metric, auto_stack=True, time_limits=long_time)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.7","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}